# OpenAI API Configuration
OPENAI_API_KEY=your_openai_api_key_here

# Database Configuration
MONGODB_URI=mongodb://localhost:27017/ai-chat

# JWT Secret
JWT_SECRET=your_jwt_secret_here

# Server Configuration
PORT=5000
NODE_ENV=development

# Frontend URL (for CORS)
FRONTEND_URL=http://localhost:5173

# OpenTelemetry Configuration
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318
OTEL_EXPORTER_OTLP_HEADERS=
OTEL_SERVICE_NAME=ai-goal-seeking-system
OTEL_SERVICE_VERSION=1.0.0
OTEL_RESOURCE_ATTRIBUTES=service.name=ai-goal-seeking-system,service.version=1.0.0,deployment.environment=development

# Tracing Configuration
ENABLE_TRACING=true
ZIPKIN_ENDPOINT=http://localhost:9411/api/v2/spans
ENABLE_METRICS=true
LOG_LEVEL=info
TRACING_EXPORTER=zipkin
OTEL_TRACES_SAMPLER_RATIO=1.0

# Azure Monitor (set only in Azure deployment / production)
# Connection string from Azure Portal -> Application Insights -> Overview
# Example: InstrumentationKey=xxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx;IngestionEndpoint=https://westus-0.in.applicationinsights.azure.com/
AZURE_MONITOR_CONNECTION_STRING=

# For Azure OTLP collector service (change host to collector service name in AKS)
# backend Deployment should set OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4318/v1/traces
